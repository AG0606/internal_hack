{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb73910-c764-4f14-95e4-c18f90b57419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import pyaudio\n",
    "import audioop\n",
    "\n",
    "# Download VADER lexicon if not already downloaded\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "class LiveSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.analyzer = SentimentIntensityAnalyzer()\n",
    "        self.timestamps = []\n",
    "        self.sentiment_values = []\n",
    "        self.loudness_values = []\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def setup_visualization(self):\n",
    "        self.fig, (self.ax1, self.ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "        self.fig.suptitle('Real-Time Voice Sentiment Analysis')\n",
    "        \n",
    "        # Sentiment plot\n",
    "        self.ax1.set_xlabel('Time (s)')\n",
    "        self.ax1.set_ylabel('Sentiment Score')\n",
    "        self.ax1.set_ylim(-1, 1)\n",
    "        self.ax1.grid(True)\n",
    "        \n",
    "        # Loudness plot\n",
    "        self.ax2.set_xlabel('Time (s)')\n",
    "        self.ax2.set_ylabel('Loudness (RMS)')\n",
    "        self.ax2.grid(True)\n",
    "    \n",
    "    def capture_and_analyze(self):\n",
    "        with sr.Microphone() as source:\n",
    "            self.recognizer.adjust_for_ambient_noise(source)\n",
    "            print(\"Listening...\")\n",
    "            audio = self.recognizer.listen(source)\n",
    "            \n",
    "            # Get raw audio data for loudness analysis\n",
    "            raw_audio = audio.get_raw_data()\n",
    "            # Calculate RMS as a measure of loudness\n",
    "            loudness = audioop.rms(raw_audio, 2)  # 2 bytes per sample\n",
    "            \n",
    "            try:\n",
    "                text = self.recognizer.recognize_google(audio)\n",
    "                sentiment_scores = self.analyzer.polarity_scores(text)\n",
    "                \n",
    "                if sentiment_scores['compound'] >= 0.05:\n",
    "                    sentiment = \"Positive\"\n",
    "                elif sentiment_scores['compound'] <= -0.05:\n",
    "                    sentiment = \"Negative\"\n",
    "                else:\n",
    "                    sentiment = \"Neutral\"\n",
    "                \n",
    "                current_time = time.time() - self.start_time\n",
    "                self.timestamps.append(current_time)\n",
    "                self.sentiment_values.append(sentiment_scores['compound'])\n",
    "                self.loudness_values.append(loudness)\n",
    "                \n",
    "                # Adjust sentiment based on loudness\n",
    "                adjusted_sentiment = self.adjust_sentiment_with_loudness(sentiment_scores['compound'], loudness)\n",
    "                \n",
    "                return text, sentiment, adjusted_sentiment, sentiment_scores, loudness\n",
    "            except:\n",
    "                return \"\", \"Unknown\", \"Unknown\", {\"compound\": 0}, 0\n",
    "    \n",
    "    def adjust_sentiment_with_loudness(self, sentiment_score, loudness):\n",
    "        # Normalize loudness to a scale of 0-1\n",
    "        max_loudness = 32767  # Maximum possible RMS value for 16-bit audio\n",
    "        normalized_loudness = min(1.0, loudness / max_loudness)\n",
    "        \n",
    "        # If loudness is high and sentiment is already leaning in a direction, amplify it\n",
    "        if normalized_loudness > 0.6:  # Threshold for \"loud\" speech\n",
    "            if sentiment_score > 0:\n",
    "                # Amplify positive sentiment for loud, positive speech\n",
    "                adjusted_score = min(1.0, sentiment_score * (1 + normalized_loudness * 0.5))\n",
    "                return adjusted_score\n",
    "            elif sentiment_score < 0:\n",
    "                # Amplify negative sentiment for loud, negative speech\n",
    "                adjusted_score = max(-1.0, sentiment_score * (1 + normalized_loudness * 0.5))\n",
    "                return adjusted_score\n",
    "        \n",
    "        return sentiment_score\n",
    "    \n",
    "    def update_visualization(self, sentiment, score, loudness):\n",
    "        # Clear previous plots\n",
    "        self.ax1.clear()\n",
    "        self.ax2.clear()\n",
    "        \n",
    "        # Update sentiment plot\n",
    "        self.ax1.plot(self.timestamps, self.sentiment_values, 'b-')\n",
    "        self.ax1.set_title(f'Current Sentiment: {sentiment} (Score: {score:.2f})')\n",
    "        self.ax1.set_xlabel('Time (s)')\n",
    "        self.ax1.set_ylabel('Sentiment Score')\n",
    "        self.ax1.set_ylim(-1, 1)\n",
    "        self.ax1.grid(True)\n",
    "        \n",
    "        # Update loudness plot\n",
    "        self.ax2.plot(self.timestamps, self.loudness_values, 'r-')\n",
    "        self.ax2.set_title(f'Current Loudness: {loudness}')\n",
    "        self.ax2.set_xlabel('Time (s)')\n",
    "        self.ax2.set_ylabel('Loudness (RMS)')\n",
    "        self.ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.pause(0.01)\n",
    "    \n",
    "    def extract_audio_features(self, audio):\n",
    "        # Convert audio to numpy array\n",
    "        audio_data = np.array(audio.get_array_of_samples())\n",
    "        \n",
    "        # Extract features\n",
    "        features = {\n",
    "            \"volume\": np.mean(np.abs(audio_data)),\n",
    "            \"zero_crossings\": np.sum(np.diff(np.signbit(audio_data))),\n",
    "            \"energy\": np.sum(audio_data**2) / len(audio_data),\n",
    "            \"max_amplitude\": np.max(np.abs(audio_data))\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def run(self):\n",
    "        self.setup_visualization()\n",
    "        \n",
    "        while True:\n",
    "            text, sentiment, adjusted_sentiment, scores, loudness = self.capture_and_analyze()\n",
    "            \n",
    "            if text:\n",
    "                self.update_visualization(sentiment, scores[\"compound\"], loudness)\n",
    "                \n",
    "                print(f\"Text: {text}\")\n",
    "                print(f\"Raw Sentiment: {sentiment} (Score: {scores['compound']:.2f})\")\n",
    "                print(f\"Adjusted Sentiment (with loudness): {adjusted_sentiment:.2f}\")\n",
    "                print(f\"Loudness: {loudness}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyzer = LiveSentimentAnalyzer()\n",
    "    analyzer.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634f753-23ed-423f-a3f9-628c25044445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
